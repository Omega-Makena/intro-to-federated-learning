{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Flower Framework\n",
    "\n",
    "This notebook provides a hands-on introduction to the Flower federated learning framework.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. What is Flower and why use it\n",
    "2. Core concepts: Clients, Server, and Strategies\n",
    "3. Building a simple federated learning client\n",
    "4. Understanding the federated learning workflow\n",
    "5. Running your first federated learning simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Flower version: {fl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Flower?\n",
    "\n",
    "Flower (flwr) is a federated learning framework that makes it easy to:\n",
    "- Build federated learning systems\n",
    "- Work with any ML framework (PyTorch, TensorFlow, JAX, etc.)\n",
    "- Scale from simulation to production\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Client**: Trains model on local data\n",
    "2. **Server**: Coordinates training and aggregates updates\n",
    "3. **Strategy**: Defines how to aggregate client updates (e.g., FedAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Example: Federated Averaging\n",
    "\n",
    "Let's create a simple neural network and train it using federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural network\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim=10, hidden_dim=20, output_dim=2):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = SimpleModel()\n",
    "print(\"Model created:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a Flower Client\n",
    "\n",
    "A Flower client needs to implement three main methods:\n",
    "- `get_parameters()`: Return current model parameters\n",
    "- `fit()`: Train model on local data\n",
    "- `evaluate()`: Evaluate model on local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Simple Flower client for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_data, test_data):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return model parameters as NumPy arrays.\"\"\"\n",
    "        return [param.cpu().detach().numpy() for param in self.model.parameters()]\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"Set model parameters from NumPy arrays.\"\"\"\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train model on local data.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        # Simple training loop (1 epoch)\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model.train()\n",
    "        for X, y in self.train_data:\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return self.get_parameters(config={}), len(self.train_data), {}\n",
    "    \n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate model on local data.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_data:\n",
    "                output = self.model(X)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        return total_loss, len(self.test_data), {\"accuracy\": accuracy}\n",
    "\n",
    "print(\"FlowerClient class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Synthetic Data\n",
    "\n",
    "Let's create some synthetic data to demonstrate federated learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_data(n_samples=100, n_features=10, n_classes=2):\n",
    "    \"\"\"Create synthetic data for demonstration.\"\"\"\n",
    "    X = torch.randn(n_samples, n_features)\n",
    "    y = torch.randint(0, n_classes, (n_samples,))\n",
    "    return [(X, y)]  # Return as list of batches\n",
    "\n",
    "# Create data for 3 clients\n",
    "print(\"Creating data for 3 clients...\")\n",
    "client_datasets = []\n",
    "for i in range(3):\n",
    "    train_data = create_synthetic_data(n_samples=100)\n",
    "    test_data = create_synthetic_data(n_samples=20)\n",
    "    client_datasets.append((train_data, test_data))\n",
    "    print(f\"  Client {i}: 100 train samples, 20 test samples\")\n",
    "\n",
    "print(\"Data created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding the Workflow\n",
    "\n",
    "### Federated Learning Process:\n",
    "\n",
    "```\n",
    "Round 1:\n",
    "  Server → Clients: Send initial model\n",
    "  Clients: Train locally\n",
    "  Clients → Server: Send updates\n",
    "  Server: Aggregate updates (FedAvg)\n",
    "  \n",
    "Round 2:\n",
    "  Server → Clients: Send updated model\n",
    "  ...\n",
    "  \n",
    "Repeat for N rounds\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Data stays local**: Never leaves the client\n",
    "2. **Model updates only**: Only weights/gradients are shared\n",
    "3. **Aggregation**: Server combines updates (weighted average)\n",
    "4. **Iterative**: Process repeats for multiple rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Flower Simulation\n",
    "\n",
    "Flower provides a simulation mode to test federated learning on a single machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.simulation import start_simulation\n",
    "\n",
    "# Create client factory function\n",
    "def client_fn(cid: str):\n",
    "    \"\"\"Create a client with given ID.\"\"\"\n",
    "    client_id = int(cid)\n",
    "    train_data, test_data = client_datasets[client_id]\n",
    "    \n",
    "    # Create new model for this client\n",
    "    client_model = SimpleModel()\n",
    "    \n",
    "    return FlowerClient(client_model, train_data, test_data).to_client()\n",
    "\n",
    "print(\"Client factory function created!\")\n",
    "print(\"\\nYou can now run simulation with:\")\n",
    "print(\"\"\"\\nstart_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=3,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=fl.server.strategy.FedAvg(),\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Flower is framework-agnostic**: Works with PyTorch, TensorFlow, etc.\n",
    "2. **Simple API**: Only need to implement 3 methods (get_parameters, fit, evaluate)\n",
    "3. **Privacy-preserving**: Data never leaves clients\n",
    "4. **Flexible**: Can customize aggregation strategies\n",
    "5. **Scalable**: From simulation to production\n",
    "\n",
    "### Client Responsibilities:\n",
    "- Hold local data\n",
    "- Train model locally\n",
    "- Send updates (not data!)\n",
    "\n",
    "### Server Responsibilities:\n",
    "- Coordinate training rounds\n",
    "- Select clients\n",
    "- Aggregate updates\n",
    "- Maintain global model\n",
    "\n",
    "### Strategies:\n",
    "- **FedAvg**: Weighted average of client models\n",
    "- **FedProx**: Handles heterogeneous data\n",
    "- **Custom**: Build your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "Ready to move forward? Check out:\n",
    "\n",
    "1. **Notebook 2**: Complete credit fraud detection example\n",
    "2. **Documentation**: `docs/FLOWER_BASICS.md` for detailed reference\n",
    "3. **Source code**: `src/client.py` and `src/server.py` for production-ready implementation\n",
    "4. **Run script**: `./run_federated_learning.sh` to run the full simulation\n",
    "\n",
    "### Try it yourself:\n",
    "\n",
    "```bash\n",
    "# Start server\n",
    "python src/server.py\n",
    "\n",
    "# In separate terminals, start clients\n",
    "python src/client.py --client-id 0\n",
    "python src/client.py --client-id 1\n",
    "python src/client.py --client-id 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Flower Documentation](https://flower.dev/docs/)\n",
    "- [Flower Examples](https://github.com/adap/flower/tree/main/examples)\n",
    "- [Federated Learning Paper](https://arxiv.org/abs/1602.05629)\n",
    "- [This Repository](https://github.com/Omega-Makena/intro-to-federated-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
